import os
import sys
import io
import warnings
import contextlib
import cv2
import numpy as np
from math import sqrt, atan2, degrees
from PIL import Image, ImageEnhance
import json
import re

# ============================================================
# C·∫§U H√åNH M√îI TR∆Ø·ªúNG - PH·∫¢I ƒê·∫∂T TR∆Ø·ªöC KHI IMPORT PADDLEOCR
# ============================================================

# T·∫Øt ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn model hosters (ti·∫øt ki·ªám v√†i gi√¢y)
os.environ['DISABLE_MODEL_SOURCE_CHECK'] = 'True'

# T·∫Øt c√°c log kh√¥ng c·∫ßn thi·∫øt c·ªßa Paddle  
os.environ['GLOG_minloglevel'] = '3'      # Ch·ªâ hi·ªán FATAL
os.environ['FLAGS_call_stack_level'] = '0'
os.environ['PADDLE_PDX_SILENT_MODE'] = '1'  # T·∫Øt log c·ªßa PaddleX

# T·∫Øt warnings
warnings.filterwarnings('ignore')

# ============================================================
# HELPER: Suppress noisy output t·ª´ PaddleOCR
# ============================================================
@contextlib.contextmanager
def suppress_output():
    """T·∫°m th·ªùi t·∫Øt stdout v√† stderr ƒë·ªÉ ·∫©n th√¥ng b√°o kh√¥ng c·∫ßn thi·∫øt"""
    old_stdout = sys.stdout
    old_stderr = sys.stderr
    try:
        sys.stdout = io.StringIO()
        sys.stderr = io.StringIO()
        yield
    finally:
        sys.stdout = old_stdout
        sys.stderr = old_stderr

# Fix encoding cho Windows
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# Import PaddleOCR SAU KHI ƒë√£ set env vars (v·ªõi suppress output)
with suppress_output():
    from paddleocr import PaddleOCR
import tkinter as tk
from tkinter import filedialog
import time

# ============================================================
# BI·∫æN GLOBAL
# ============================================================
_ocr_instance = None
ROI_INFO_PATH = "roi_data/roi_info.json"
MACHINE_SCREENS_PATH = "roi_data/machine_screens.json"
IOU_THRESHOLD = 0.10  # Ng∆∞·ª°ng IoU 10%

# ============================================================
# MACHINE SCREENS FUNCTIONS
# ============================================================

def load_machine_screens():
    """ƒê·ªçc file machine_screens.json"""
    if not os.path.exists(MACHINE_SCREENS_PATH):
        print(f"   ‚ö† Kh√¥ng t√¨m th·∫•y file: {MACHINE_SCREENS_PATH}")
        return None
    
    with open(MACHINE_SCREENS_PATH, 'r', encoding='utf-8-sig') as f:
        return json.load(f)

def select_area(machine_screens):
    """Ch·ªçn khu v·ª±c (F1, F4, ...)"""
    if not machine_screens or 'areas' not in machine_screens:
        print("   ‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin khu v·ª±c trong machine_screens.json")
        return None
    
    areas = machine_screens['areas']
    area_list = list(areas.keys())
    
    print("\n" + "="*50)
    print("üìç CH·ªåN KHU V·ª∞C")
    print("="*50)
    for i, area_code in enumerate(area_list, 1):
        area_name = areas[area_code].get('name', area_code)
        machine_count = len(areas[area_code].get('machines', {}))
        print(f"   {i}. {area_code} - {area_name} ({machine_count} m√°y)")
    print("   0. Tho√°t")
    print("-"*50)
    
    while True:
        try:
            choice = input("Nh·∫≠p s·ªë th·ª© t·ª± khu v·ª±c (0 ƒë·ªÉ tho√°t): ").strip()
            if choice == '0' or choice == '':
                return None
            
            index = int(choice) - 1
            if 0 <= index < len(area_list):
                selected_area = area_list[index]
                area_name = areas[selected_area].get('name', selected_area)
                print(f"   ‚úì ƒê√£ ch·ªçn: {selected_area} - {area_name}")
                return selected_area
            else:
                print("   ‚ö† L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i.")
        except ValueError:
            print("   ‚ö† Vui l√≤ng nh·∫≠p s·ªë.")

def select_machine(machine_screens, area):
    """Ch·ªçn m√£ m√°y trong khu v·ª±c ƒë√£ ch·ªçn"""
    if not machine_screens or 'areas' not in machine_screens:
        return None
    
    if area not in machine_screens['areas']:
        print(f"   ‚ö† Kh√¥ng t√¨m th·∫•y khu v·ª±c: {area}")
        return None
    
    machines = machine_screens['areas'][area].get('machines', {})
    if not machines:
        print(f"   ‚ö† Kh√¥ng c√≥ m√°y n√†o trong khu v·ª±c {area}")
        return None
    
    machine_list = list(machines.keys())
    
    print("\n" + "="*50)
    print(f"üîß CH·ªåN M√É M√ÅY (Khu v·ª±c {area})")
    print("="*50)
    for i, machine_code in enumerate(machine_list, 1):
        machine_info = machines[machine_code]
        machine_name = machine_info.get('name', machine_code)
        machine_type = machine_info.get('type', 'N/A')
        screen_count = len(machine_info.get('screens', []))
        print(f"   {i}. {machine_code} - {machine_name} (Type: {machine_type}, {screen_count} m√†n h√¨nh)")
    print("   0. Quay l·∫°i ch·ªçn khu v·ª±c")
    print("-"*50)
    
    while True:
        try:
            choice = input("Nh·∫≠p s·ªë th·ª© t·ª± m√°y (0 ƒë·ªÉ quay l·∫°i): ").strip()
            if choice == '0' or choice == '':
                return None
            
            index = int(choice) - 1
            if 0 <= index < len(machine_list):
                selected_machine = machine_list[index]
                machine_name = machines[selected_machine].get('name', selected_machine)
                print(f"   ‚úì ƒê√£ ch·ªçn: {selected_machine} - {machine_name}")
                return selected_machine
            else:
                print("   ‚ö† L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i.")
        except ValueError:
            print("   ‚ö† Vui l√≤ng nh·∫≠p s·ªë.")

# ============================================================
# ROI MATCHING & IoU FUNCTIONS
# ============================================================

def load_roi_info():
    """ƒê·ªçc file roi_info.json"""
    if not os.path.exists(ROI_INFO_PATH):
        print(f"   ‚ö† Kh√¥ng t√¨m th·∫•y file: {ROI_INFO_PATH}")
        return None
    
    with open(ROI_INFO_PATH, 'r', encoding='utf-8') as f:
        return json.load(f)

def normalize_text(text):
    """
    Chu·∫©n h√≥a text ƒë·ªÉ so s√°nh fuzzy matching
    - Lo·∫°i b·ªè d·∫•u : v√† kho·∫£ng tr·∫Øng th·ª´a
    - Chuy·ªÉn uppercase
    - Chu·∫©n h√≥a ƒë·ªãnh d·∫°ng "ST14 - LEAK" ‚Üí "ST14-LEAK" (lo·∫°i b·ªè space quanh d·∫•u g·∫°ch ngang)
    """
    if not text:
        return ""
    # Chuy·ªÉn uppercase v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng ƒë·∫ßu/cu·ªëi
    normalized = text.strip().upper()
    # Lo·∫°i b·ªè d·∫•u : ·ªü cu·ªëi
    normalized = normalized.rstrip(':')
    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng xung quanh d·∫•u g·∫°ch ngang (ST14 - LEAK ‚Üí ST14-LEAK)
    normalized = re.sub(r'\s*-\s*', '-', normalized)
    # G·ªôp nhi·ªÅu kho·∫£ng tr·∫Øng th√†nh 1
    normalized = re.sub(r'\s+', ' ', normalized)
    return normalized

def fuzzy_match(text1, text2, threshold=0.75):
    """
    So s√°nh fuzzy gi·ªØa 2 chu·ªói, tr·∫£ v·ªÅ True n·∫øu ƒë·ªô t∆∞∆°ng ƒë·ªìng >= threshold
    S·ª≠ d·ª•ng thu·∫≠t to√°n Levenshtein distance
    
    L∆ØU √ù: threshold = 0.75 ƒë·ªÉ tr√°nh false positives nh∆∞:
    - "PRESENCE CHECK" matching v·ªõi "ST04-PARTS LOADED PRESENCE CHECK"
    """
    s1 = normalize_text(text1)
    s2 = normalize_text(text2)
    
    if not s1 or not s2:
        return False
    
    len1, len2 = len(s1), len(s2)
    min_len = min(len1, len2)
    max_len = max(len1, len2)
    
    # Ki·ªÉm tra m·ªôt chu·ªói ch·ª©a chu·ªói kia - CH·ªà cho ph√©p n·∫øu ƒë·ªô d√†i g·∫ßn nhau
    # Tr√°nh tr∆∞·ªùng h·ª£p "PRESENCE CHECK" match v·ªõi "ST04-PARTS LOADED PRESENCE CHECK"
    if s1 in s2 or s2 in s1:
        # Ch·ªâ ch·∫•p nh·∫≠n n·∫øu chu·ªói ng·∫Øn h∆°n chi·∫øm √≠t nh·∫•t 70% chu·ªói d√†i h∆°n
        length_ratio = min_len / max_len
        if length_ratio >= 0.7:
            return True
        # N·∫øu kh√¥ng, ti·∫øp t·ª•c ki·ªÉm tra b·∫±ng Levenshtein
    
    # N·∫øu ƒë·ªô d√†i kh√°c nhau qu√° nhi·ªÅu (>40%), kh√¥ng kh·ªõp
    if abs(len1 - len2) > max_len * 0.4:
        return False
    
    # T√≠nh Levenshtein distance
    # T·∫°o ma tr·∫≠n
    dp = [[0] * (len2 + 1) for _ in range(len1 + 1)]
    
    for i in range(len1 + 1):
        dp[i][0] = i
    for j in range(len2 + 1):
        dp[0][j] = j
    
    for i in range(1, len1 + 1):
        for j in range(1, len2 + 1):
            if s1[i-1] == s2[j-1]:
                dp[i][j] = dp[i-1][j-1]
            else:
                dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])
    
    distance = dp[len1][len2]
    similarity = 1 - (distance / max_len)
    
    return similarity >= threshold

def find_matching_screen(ocr_data, roi_info, selected_area=None, selected_machine=None, debug=True):
    """
    T√¨m screen v√† sub_page ph√π h·ª£p nh·∫•t d·ª±a tr√™n Special_rois
    
    H·ªó tr·ª£ c·∫•u tr√∫c m·ªõi:
    machines > area (F1) > machine_code (IE-F1-CWA01) > screens > screen_name > sub_pages > page_num
    
    Args:
        ocr_data: D·ªØ li·ªáu OCR ƒë√£ tr√≠ch xu·∫•t
        roi_info: D·ªØ li·ªáu t·ª´ roi_info.json
        selected_area: Khu v·ª±c ƒë√£ ch·ªçn (F1, F4, ...) - n·∫øu None s·∫Ω duy·ªát t·∫•t c·∫£
        selected_machine: M√£ m√°y ƒë√£ ch·ªçn (IE-F1-CWA01, ...) - n·∫øu None s·∫Ω duy·ªát t·∫•t c·∫£ trong area
        debug: Hi·ªÉn th·ªã th√¥ng tin debug
    
    Tr·∫£ v·ªÅ: (area, machine_code, screen_name, sub_page, sub_page_data, match_count, match_percentage)
    """
    if not roi_info or 'machines' not in roi_info:
        return None, None, None, None, None, 0, 0
    
    # L·∫•y t·∫•t c·∫£ text t·ª´ OCR (ƒë√£ chu·∫©n h√≥a)
    ocr_texts = [normalize_text(item['text']) for item in ocr_data]
    
    if debug:
        print(f"\n   üìù OCR detected {len(ocr_texts)} text items")
        if selected_area and selected_machine:
            print(f"   üéØ L·ªçc theo: {selected_area}/{selected_machine}")
    
    best_match = None
    best_match_count = 0
    best_match_percentage = 0
    
    # L∆∞u t·∫•t c·∫£ k·∫øt qu·∫£ matching ƒë·ªÉ debug
    all_matches = []
    
    # Duy·ªát qua c·∫•u tr√∫c: machines > area > machine_code > screens
    for area, area_data in roi_info['machines'].items():
        # N·∫øu ƒë√£ ch·ªçn area, ch·ªâ duy·ªát area ƒë√≥
        if selected_area and area != selected_area:
            continue
        
        # Ki·ªÉm tra xem area_data c√≥ ph·∫£i l√† dict ch·ª©a machine_codes kh√¥ng
        if not isinstance(area_data, dict):
            continue
        
        for machine_code, machine_data in area_data.items():
            # N·∫øu ƒë√£ ch·ªçn machine, ch·ªâ duy·ªát machine ƒë√≥
            if selected_machine and machine_code != selected_machine:
                continue
            
            # B·ªè qua n·∫øu kh√¥ng ph·∫£i dict ho·∫∑c kh√¥ng c√≥ screens
            if not isinstance(machine_data, dict) or 'screens' not in machine_data:
                continue
            
            for screen_name, screen_data in machine_data['screens'].items():
                # Ki·ªÉm tra c·∫•u tr√∫c v·ªõi sub_pages
                if 'sub_pages' in screen_data:
                    # Duy·ªát qua t·ª´ng sub_page
                    for sub_page, sub_page_data in screen_data['sub_pages'].items():
                        if 'Special_rois' not in sub_page_data:
                            continue
                        
                        special_rois = sub_page_data['Special_rois']
                        match_count = 0
                        matched_rois = []
                        
                        # ƒê·∫øm s·ªë l∆∞·ª£ng Special_rois kh·ªõp v·ªõi OCR results
                        for special_roi in special_rois:
                            special_roi_normalized = normalize_text(special_roi)
                            
                            for ocr_text in ocr_texts:
                                if fuzzy_match(special_roi_normalized, ocr_text):
                                    match_count += 1
                                    matched_rois.append(special_roi)
                                    break  # M·ªói Special_roi ch·ªâ ƒë·∫øm 1 l·∫ßn
                        
                        # T√≠nh ph·∫ßn trƒÉm kh·ªõp
                        if len(special_rois) > 0:
                            match_percentage = (match_count / len(special_rois)) * 100
                        else:
                            match_percentage = 0
                        
                        # L∆∞u k·∫øt qu·∫£ ƒë·ªÉ debug
                        all_matches.append({
                            'area': area,
                            'machine': machine_code,
                            'screen': screen_name,
                            'sub_page': sub_page,
                            'special_rois': special_rois,
                            'match_count': match_count,
                            'match_percentage': match_percentage,
                            'matched_rois': matched_rois
                        })
                        
                        # C·∫≠p nh·∫≠t best match
                        if match_count > best_match_count or (match_count == best_match_count and match_percentage > best_match_percentage):
                            best_match_count = match_count
                            best_match_percentage = match_percentage
                            best_match = (area, machine_code, screen_name, sub_page, sub_page_data)
                else:
                    # C·∫•u tr√∫c c≈© (kh√¥ng c√≥ sub_pages) - t∆∞∆°ng th√≠ch ng∆∞·ª£c
                    if 'Special_rois' not in screen_data:
                        continue
                    
                    special_rois = screen_data['Special_rois']
                    match_count = 0
                    matched_rois = []
                    
                    # ƒê·∫øm s·ªë l∆∞·ª£ng Special_rois kh·ªõp v·ªõi OCR results
                    for special_roi in special_rois:
                        special_roi_normalized = normalize_text(special_roi)
                        
                        for ocr_text in ocr_texts:
                            if fuzzy_match(special_roi_normalized, ocr_text):
                                match_count += 1
                                matched_rois.append(special_roi)
                                break
                    
                    # T√≠nh ph·∫ßn trƒÉm kh·ªõp
                    if len(special_rois) > 0:
                        match_percentage = (match_count / len(special_rois)) * 100
                    else:
                        match_percentage = 0
                    
                    # L∆∞u k·∫øt qu·∫£ ƒë·ªÉ debug
                    all_matches.append({
                        'area': area,
                        'machine': machine_code,
                        'screen': screen_name,
                        'sub_page': '1',
                        'special_rois': special_rois,
                        'match_count': match_count,
                        'match_percentage': match_percentage,
                        'matched_rois': matched_rois
                    })
                    
                    # C·∫≠p nh·∫≠t best match (sub_page = "1" cho c·∫•u tr√∫c c≈©)
                    if match_count > best_match_count or (match_count == best_match_count and match_percentage > best_match_percentage):
                        best_match_count = match_count
                        best_match_percentage = match_percentage
                        best_match = (area, machine_code, screen_name, "1", screen_data)
    
    # In debug info v·ªÅ t·∫•t c·∫£ matches
    if debug and all_matches:
        print(f"\n   üîç Screen matching results:")
        for m in all_matches:
            status = "‚úì" if m['match_count'] > 0 else "‚úó"
            print(f"      {status} {m['area']}/{m['machine']}/{m['screen']}/sub-page {m['sub_page']}: "
                  f"{m['match_count']}/{len(m['special_rois'])} matches ({m['match_percentage']:.0f}%)")
            if m['matched_rois']:
                print(f"         Matched: {m['matched_rois']}")
    
    if best_match:
        # Tr·∫£ v·ªÅ: (area, machine_code, screen_name, sub_page, sub_page_data, match_count, match_percentage)
        return best_match[0], best_match[1], best_match[2], best_match[3], best_match[4], best_match_count, best_match_percentage
    
    return None, None, None, None, None, 0, 0

def polygon_to_normalized_bbox(polygon, img_width, img_height):
    """
    Chuy·ªÉn ƒë·ªïi polygon t·ª´ PaddleOCR sang normalized bounding box [x1, y1, x2, y2]
    polygon: [[x1,y1], [x2,y2], [x3,y3], [x4,y4]] (4 g√≥c c·ªßa text box)
    """
    if not polygon or len(polygon) < 4:
        return None
    
    # L·∫•y t·ªça ƒë·ªô min/max
    xs = [p[0] for p in polygon]
    ys = [p[1] for p in polygon]
    
    x_min = min(xs)
    y_min = min(ys)
    x_max = max(xs)
    y_max = max(ys)
    
    # Normalize
    norm_x1 = x_min / img_width
    norm_y1 = y_min / img_height
    norm_x2 = x_max / img_width
    norm_y2 = y_max / img_height
    
    return [norm_x1, norm_y1, norm_x2, norm_y2]

def calculate_iou(box1, box2):
    """
    T√≠nh IoU (Intersection over Union) gi·ªØa 2 bounding boxes
    box format: [x1, y1, x2, y2] (normalized)
    """
    # T√≠nh t·ªça ƒë·ªô intersection
    x1_inter = max(box1[0], box2[0])
    y1_inter = max(box1[1], box2[1])
    x2_inter = min(box1[2], box2[2])
    y2_inter = min(box1[3], box2[3])
    
    # T√≠nh di·ªán t√≠ch intersection
    inter_width = max(0, x2_inter - x1_inter)
    inter_height = max(0, y2_inter - y1_inter)
    intersection_area = inter_width * inter_height
    
    # T√≠nh di·ªán t√≠ch c·ªßa m·ªói box
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    # T√≠nh union
    union_area = box1_area + box2_area - intersection_area
    
    # T√≠nh IoU
    if union_area <= 0:
        return 0.0
    
    iou = intersection_area / union_area
    return iou

def filter_ocr_by_roi(ocr_data, sub_page_data, img_width, img_height):
    """
    L·ªçc k·∫øt qu·∫£ OCR d·ª±a tr√™n IoU v·ªõi c√°c ROIs c·ªßa sub_page
    H·ªó tr·ª£ c·∫•u tr√∫c m·ªõi v·ªõi sub_pages
    Tr·∫£ v·ªÅ: list c√°c k·∫øt qu·∫£ OCR ƒë√£ ƒë∆∞·ª£c l·ªçc v·ªõi th√¥ng tin ROI t∆∞∆°ng ·ª©ng
    """
    if not sub_page_data:
        return []
    
    # L·∫•y Rois t·ª´ sub_page_data (h·ªó tr·ª£ c·∫£ c·∫•u tr√∫c c≈© v√† m·ªõi)
    rois = sub_page_data.get('Rois', [])
    if not rois:
        return []
    filtered_results = []
    
    for ocr_item in ocr_data:
        polygon = ocr_item.get('bbox', [])
        if not polygon:
            continue
        
        # Chuy·ªÉn ƒë·ªïi polygon sang normalized bbox
        ocr_bbox = polygon_to_normalized_bbox(polygon, img_width, img_height)
        if not ocr_bbox:
            continue
        
        # T√¨m ROI c√≥ IoU cao nh·∫•t
        best_iou = 0
        best_roi_name = None
        best_roi_coords = None
        
        for roi in rois:
            roi_coords = roi.get('coordinates', [])
            if len(roi_coords) != 4:
                continue
            
            # roi_coords format: [x1, y1, x2, y2] (normalized)
            iou = calculate_iou(ocr_bbox, roi_coords)
            
            if iou > best_iou:
                best_iou = iou
                best_roi_name = roi.get('name', 'Unknown')
                best_roi_coords = roi_coords
        
        # Ch·ªâ gi·ªØ l·∫°i n·∫øu IoU > threshold
        if best_iou >= IOU_THRESHOLD:
            filtered_results.append({
                'text': ocr_item['text'],
                'confidence': ocr_item['confidence'],
                'bbox': polygon,
                'normalized_bbox': ocr_bbox,
                'matched_roi': best_roi_name,
                'roi_coords': best_roi_coords,
                'iou': best_iou
            })
    
    return filtered_results

# ============================================================
# HMI DETECTION FUNCTIONS (t·ª´ hmi_image_detector.py)
# ============================================================

def enhance_image_for_hmi(image):
    """C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ·∫£nh tr∆∞·ªõc khi ph√°t hi·ªán c·∫°nh"""
    # Chuy·ªÉn t·ª´ OpenCV (BGR) sang PIL (RGB) ƒë·ªÉ √°p d·ª•ng ImageEnhance
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(image_rgb)
    
    # TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n v·ªõi PIL
    enhancer = ImageEnhance.Contrast(pil_image)
    enhanced_pil = enhancer.enhance(2)  # TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n l√™n 50%
    
    # Chuy·ªÉn l·∫°i v·ªÅ ƒë·ªãnh d·∫°ng OpenCV
    enhanced_image = cv2.cvtColor(np.array(enhanced_pil), cv2.COLOR_RGB2BGR)
    
    # Ti·∫øp t·ª•c quy tr√¨nh x·ª≠ l√Ω ·∫£nh nh∆∞ tr∆∞·ªõc
    gray = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2GRAY)
    # TƒÉng clip limit ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô t∆∞∆°ng ph·∫£n
    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(11, 11))
    enhanced = clahe.apply(gray)
    
    # TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n
    enhanced = cv2.convertScaleAbs(enhanced, alpha=1.2, beta=0)
    
    # L√†m m·ªãn ·∫£nh v·ªõi kernel nh·ªè h∆°n ƒë·ªÉ gi·ªØ nguy√™n c·∫°nh s·∫Øc n√©t h∆°n
    blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)
    return blurred, enhanced

def adaptive_edge_detection(image):
    """Ph√°t hi·ªán c·∫°nh v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p v√† k·∫øt h·ª£p k·∫øt qu·∫£"""
    median_val = np.median(image)
    # Gi·∫£m ng∆∞·ª°ng ƒë·ªÉ tƒÉng ƒë·ªô nh·∫°y c·∫£m ph√°t hi·ªán c·∫°nh
    lower = int(max(0, (1.0 - 0.33) * median_val))
    upper = int(min(255, (1.0 + 0.33) * median_val))
    canny_edges = cv2.Canny(image, lower, upper)
    
    # S·ª≠ d·ª•ng kernel l·ªõn h∆°n cho b·ªô l·ªçc Sobel
    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)
    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)
    sobel_edges = cv2.magnitude(sobelx, sobely)
    sobel_edges = cv2.normalize(sobel_edges, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
    # Gi·∫£m ng∆∞·ª°ng sobel ƒë·ªÉ b·∫Øt ƒë∆∞·ª£c nhi·ªÅu c·∫°nh h∆°n
    _, sobel_edges = cv2.threshold(sobel_edges, 80, 255, cv2.THRESH_BINARY)
    
    # K·∫øt h·ª£p c·∫£ hai ph∆∞∆°ng ph√°p ph√°t hi·ªán c·∫°nh
    combined_edges = cv2.bitwise_or(canny_edges, sobel_edges)
    
    # TƒÉng s·ªë l·∫ßn gi√£n n·ªü ƒë·ªÉ k·∫øt n·ªëi c√°c c·∫°nh b·ªã ƒë·ª©t ƒëo·∫°n
    kernel = np.ones((3, 3), np.uint8)
    dilated_edges = cv2.dilate(combined_edges, kernel, iterations=2)
    final_edges = cv2.erode(dilated_edges, kernel, iterations=1)
    
    return canny_edges, sobel_edges, final_edges

def process_lines(lines, img_shape, min_length=20, max_lines_per_direction=30):
    """X·ª≠ l√Ω v√† nh√≥m c√°c ƒë∆∞·ªùng th·∫≥ng theo h∆∞·ªõng ngang/d·ªçc, gi·ªõi h·∫°n s·ªë l∆∞·ª£ng ƒë∆∞·ªùng"""
    if lines is None:
        return [], []
    
    horizontal_lines = []
    vertical_lines = []
    
    all_h_lines = []
    all_v_lines = []
    
    height, width = img_shape[:2]
    min_dimension = min(height, width)
    
    # Gi·∫£m ƒë·ªô d√†i t·ªëi thi·ªÉu ƒë·ªÉ ph√°t hi·ªán nhi·ªÅu ƒë∆∞·ªùng h∆°n
    min_length = max(min_length, int(min_dimension * 0.02))
    
    for line in lines:
        x1, y1, x2, y2 = line[0]
        length = sqrt((x2-x1)**2 + (y2-y1)**2)
        
        if length < min_length:
            continue
        
        # T√≠nh g√≥c c·ªßa ƒë∆∞·ªùng th·∫≥ng
        if x2 != x1:
            angle = degrees(atan2(y2-y1, x2-x1))
        else:
            angle = 90  # ƒê∆∞·ªùng d·ªçc
        
        # M·ªü r·ªông ph·∫°m vi ph√¢n lo·∫°i ƒë∆∞·ªùng ngang/d·ªçc
        if abs(angle) < 40 or abs(angle) > 140:  # ƒê∆∞·ªùng ngang
            all_h_lines.append([x1, y1, x2, y2, angle, length])
        elif abs(angle - 90) < 40 or abs(angle + 90) < 40:  # ƒê∆∞·ªùng d·ªçc
            all_v_lines.append([x1, y1, x2, y2, angle, length])
    
    # S·∫Øp x·∫øp theo ƒë·ªô d√†i
    all_h_lines.sort(key=lambda x: x[5], reverse=True)
    all_v_lines.sort(key=lambda x: x[5], reverse=True)
    
    # ƒê·∫£m b·∫£o c√≥ ƒë·ªß s·ªë l∆∞·ª£ng ƒë∆∞·ªùng ngang v√† d·ªçc t·ªëi thi·ªÉu
    min_lines = min(4, len(all_h_lines))
    horizontal_lines = [line[:5] for line in all_h_lines[:max(min_lines, max_lines_per_direction)]]
    
    min_lines = min(4, len(all_v_lines))
    vertical_lines = [line[:5] for line in all_v_lines[:max(min_lines, max_lines_per_direction)]]
    
    return horizontal_lines, vertical_lines

def extend_lines(lines, width, height):
    """K√©o d√†i c√°c ƒë∆∞·ªùng th·∫≥ng ƒë·∫øn bi√™n c·ªßa ·∫£nh"""
    extended_lines = []
    
    for x1, y1, x2, y2, angle in lines:
        # X·ª≠ l√Ω ƒë∆∞·ªùng d·ªçc (x kh√¥ng ƒë·ªïi)
        if abs(x2 - x1) < 5:  # ƒê∆∞·ªùng d·ªçc ho·∫∑c g·∫ßn d·ªçc
            extended_lines.append([x1, 0, x1, height - 1, angle])
            continue
            
        # X·ª≠ l√Ω ƒë∆∞·ªùng ngang (y kh√¥ng ƒë·ªïi)
        if abs(y2 - y1) < 5:  # ƒê∆∞·ªùng ngang ho·∫∑c g·∫ßn ngang
            extended_lines.append([0, y1, width - 1, y1, angle])
            continue
        
        # X·ª≠ l√Ω c√°c ƒë∆∞·ªùng xi√™n
        m = (y2 - y1) / (x2 - x1)  # H·ªá s·ªë g√≥c
        b = y1 - m * x1  # H·ªá s·ªë t·ª± do
        
        # T√≠nh to√°n giao ƒëi·ªÉm v·ªõi c√°c c·∫°nh c·ªßa ·∫£nh
        intersections = []
        
        # Giao v·ªõi c·∫°nh tr√°i (x=0)
        y_left = m * 0 + b
        if 0 <= y_left < height:
            intersections.append((0, int(y_left)))
            
        # Giao v·ªõi c·∫°nh ph·∫£i (x=width-1)
        y_right = m * (width - 1) + b
        if 0 <= y_right < height:
            intersections.append((width - 1, int(y_right)))
            
        # Giao v·ªõi c·∫°nh tr√™n (y=0)
        if abs(m) > 1e-10:
            x_top = (0 - b) / m
            if 0 <= x_top < width:
                intersections.append((int(x_top), 0))
            
        # Giao v·ªõi c·∫°nh d∆∞·ªõi (y=height-1)
        if abs(m) > 1e-10:
            x_bottom = ((height - 1) - b) / m
            if 0 <= x_bottom < width:
                intersections.append((int(x_bottom), height - 1))
        
        # N·∫øu c√≥ ƒë·ªß hai giao ƒëi·ªÉm, t·∫°o ƒë∆∞·ªùng k√©o d√†i
        if len(intersections) >= 2:
            p1, p2 = intersections[:2]
            extended_lines.append([p1[0], p1[1], p2[0], p2[1], angle])
    
    return extended_lines

def find_intersections(horizontal_lines, vertical_lines, max_intersections=200):
    """T√¨m giao ƒëi·ªÉm c·ªßa c√°c ƒë∆∞·ªùng ngang v√† d·ªçc, gi·ªõi h·∫°n s·ªë l∆∞·ª£ng giao ƒëi·ªÉm"""
    intersections = []
    
    for h_line in horizontal_lines:
        for v_line in vertical_lines:
            if len(intersections) >= max_intersections:
                break
                
            x1_h, y1_h, x2_h, y2_h, _ = h_line
            x1_v, y1_v, x2_v, y2_v, _ = v_line
            
            # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát c·ªßa ƒë∆∞·ªùng ngang v√† d·ªçc
            if abs(y1_h - y2_h) < 5 and abs(x1_v - x2_v) < 5:
                intersections.append((int(x1_v), int(y1_h)))
                continue
            
            # S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n h∆°n ƒë·ªÉ t√¨m giao ƒëi·ªÉm
            try:
                # Chuy·ªÉn sang float ƒë·ªÉ tr√°nh tr√†n s·ªë
                x1_h, y1_h, x2_h, y2_h = float(x1_h), float(y1_h), float(x2_h), float(y2_h)
                x1_v, y1_v, x2_v, y2_v = float(x1_v), float(y1_v), float(x2_v), float(y2_v)
                
                # Ki·ªÉm tra n·∫øu ƒë∆∞·ªùng ngang g·∫ßn nh∆∞ ngang
                if abs(y2_h - y1_h) < 1e-10:
                    if abs(x2_v - x1_v) < 1e-10:
                        x_intersect = x1_v
                    else:
                        t = (y1_h - y1_v) / (y2_v - y1_v)
                        x_intersect = x1_v + t * (x2_v - x1_v)
                    
                    intersections.append((int(x_intersect), int(y1_h)))
                    continue
                
                # Ki·ªÉm tra n·∫øu ƒë∆∞·ªùng d·ªçc g·∫ßn nh∆∞ d·ªçc
                if abs(x2_v - x1_v) < 1e-10:
                    if abs(x2_h - x1_h) < 1e-10:
                        y_intersect = y1_h
                    else:
                        t = (x1_v - x1_h) / (x2_h - x1_h)
                        y_intersect = y1_h + t * (y2_h - y1_h)
                    
                    intersections.append((int(x1_v), int(y_intersect)))
                    continue
                
                # Tr∆∞·ªùng h·ª£p t·ªïng qu√°t
                denom = (y2_v - y1_v) * (x2_h - x1_h) - (x2_v - x1_v) * (y2_h - y1_h)
                
                if abs(denom) < 1e-10:
                    continue
                
                ua = ((x2_v - x1_v) * (y1_h - y1_v) - (y2_v - y1_v) * (x1_h - x1_v)) / denom
                
                x_intersect = x1_h + ua * (x2_h - x1_h)
                y_intersect = y1_h + ua * (y2_h - y1_h)
                
                if (min(x1_h, x2_h) - 10 <= x_intersect <= max(x1_h, x2_h) + 10 and
                    min(y1_v, y2_v) - 10 <= y_intersect <= max(y1_v, y2_v) + 10):
                    intersections.append((int(x_intersect), int(y_intersect)))
            
            except (ValueError, OverflowError, ZeroDivisionError):
                continue
        
        if len(intersections) >= max_intersections:
            break
    
    return intersections

def find_largest_rectangle(intersections, img_shape):
    """T√¨m h√¨nh ch·ªØ nh·∫≠t l·ªõn nh·∫•t t·ª´ c√°c giao ƒëi·ªÉm"""
    if len(intersections) < 4:
        return None
    
    # T√¨m c√°c ƒëi·ªÉm bi√™n
    left_point = min(intersections, key=lambda p: p[0])
    right_point = max(intersections, key=lambda p: p[0])
    top_point = min(intersections, key=lambda p: p[1])
    bottom_point = max(intersections, key=lambda p: p[1])
    
    # T√≠nh to√°n c√°c g√≥c c·ªßa h√¨nh ch·ªØ nh·∫≠t l·ªõn nh·∫•t
    top_left = (left_point[0], top_point[1])
    top_right = (right_point[0], top_point[1])
    bottom_left = (left_point[0], bottom_point[1])
    bottom_right = (right_point[0], bottom_point[1])
    
    # Ki·ªÉm tra xem c√°c g√≥c c√≥ n·∫±m g·∫ßn c√°c giao ƒëi·ªÉm kh√¥ng
    threshold = 30
    
    def find_nearest_intersection(point):
        nearest = min(intersections, key=lambda p: (p[0]-point[0])**2 + (p[1]-point[1])**2)
        distance = sqrt((nearest[0]-point[0])**2 + (nearest[1]-point[1])**2)
        if distance < threshold:
            return nearest
        return point
    
    refined_top_left = find_nearest_intersection(top_left)
    refined_top_right = find_nearest_intersection(top_right)
    refined_bottom_left = find_nearest_intersection(bottom_left)
    refined_bottom_right = find_nearest_intersection(bottom_right)
    
    # T√≠nh di·ªán t√≠ch
    width = refined_top_right[0] - refined_top_left[0]
    height = refined_bottom_left[1] - refined_top_left[1]
    area = width * height
    
    # Ki·ªÉm tra k√≠ch th∆∞·ªõc h·ª£p l√Ω
    height_img, width_img = img_shape[:2]
    total_area = height_img * width_img
    
    if area < 0.01 * total_area or area > 0.9 * total_area:
        return None
    
    if width <= 0 or height <= 0:
        return None
    
    aspect_ratio = max(width, height) / (min(width, height) + 1e-6)
    if aspect_ratio > 5:
        return None
    
    return (refined_top_left, refined_top_right, refined_bottom_right, refined_bottom_left, area)

def find_rectangle_from_classified_lines(horizontal_lines, vertical_lines, img_shape):
    """T√¨m h√¨nh ch·ªØ nh·∫≠t t·ª´ c√°c ƒë∆∞·ªùng ƒë√£ ph√¢n lo·∫°i ngang v√† d·ªçc"""
    if len(horizontal_lines) < 2 or len(vertical_lines) < 2:
        return None
    
    # T√¨m ƒë∆∞·ªùng ngang tr√™n c√πng v√† d∆∞·ªõi c√πng
    top_line = min(horizontal_lines, key=lambda line: min(line[1], line[3]))
    bottom_line = max(horizontal_lines, key=lambda line: max(line[1], line[3]))
    
    # T√¨m ƒë∆∞·ªùng d·ªçc tr√°i c√πng v√† ph·∫£i c√πng
    left_line = min(vertical_lines, key=lambda line: min(line[0], line[2]))
    right_line = max(vertical_lines, key=lambda line: max(line[0], line[2]))
    
    # T√≠nh to√°n c√°c t·ªça ƒë·ªô y cho ƒë∆∞·ªùng ngang tr√™n v√† d∆∞·ªõi
    top_y = min(top_line[1], top_line[3])
    bottom_y = max(bottom_line[1], bottom_line[3])
    
    # T√≠nh to√°n c√°c t·ªça ƒë·ªô x cho ƒë∆∞·ªùng d·ªçc tr√°i v√† ph·∫£i
    left_x = min(left_line[0], left_line[2])
    right_x = max(right_line[0], right_line[2])
    
    # Ki·ªÉm tra ngang
    top_left_x = max(min(top_line[0], top_line[2]), left_x)
    top_right_x = min(max(top_line[0], top_line[2]), right_x)
    bottom_left_x = max(min(bottom_line[0], bottom_line[2]), left_x)
    bottom_right_x = min(max(bottom_line[0], bottom_line[2]), right_x)
    
    # Ki·ªÉm tra d·ªçc
    left_top_y = max(min(left_line[1], left_line[3]), top_y)
    left_bottom_y = min(max(left_line[1], left_line[3]), bottom_y)
    right_top_y = max(min(right_line[1], right_line[3]), top_y)
    right_bottom_y = min(max(right_line[1], right_line[3]), bottom_y)
    
    if (top_right_x - top_left_x < 10 or bottom_right_x - bottom_left_x < 10 or
        left_bottom_y - left_top_y < 10 or right_bottom_y - right_top_y < 10):
        return None
    
    # Ki·ªÉm tra k√≠ch th∆∞·ªõc c·ªßa h√¨nh ch·ªØ nh·∫≠t
    height, width = img_shape[:2]
    
    if left_x < 0: left_x = 0
    if top_y < 0: top_y = 0
    if right_x >= width: right_x = width - 1
    if bottom_y >= height: bottom_y = height - 1
    
    rect_width = right_x - left_x
    rect_height = bottom_y - top_y
    
    if rect_width < 20 or rect_height < 20:
        return None
    
    aspect_ratio = max(rect_width, rect_height) / (min(rect_width, rect_height) + 1e-6)
    if aspect_ratio > 5:
        return None
    
    top_left = (int(left_x), int(top_y))
    top_right = (int(right_x), int(top_y))
    bottom_right = (int(right_x), int(bottom_y))
    bottom_left = (int(left_x), int(bottom_y))
    
    area = rect_width * rect_height
    
    total_area = height * width
    if area < 0.01 * total_area or area > 0.9 * total_area:
        return None
    
    return (top_left, top_right, bottom_right, bottom_left, area)

def order_points(pts):
    """S·∫Øp x·∫øp 4 ƒëi·ªÉm theo th·ª© t·ª±: top-left, top-right, bottom-right, bottom-left"""
    rect = np.zeros((4, 2), dtype=np.float32)
    
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]  # top-left
    rect[2] = pts[np.argmax(s)]  # bottom-right
    
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]  # top-right
    rect[3] = pts[np.argmax(diff)]  # bottom-left
    
    return rect

def extract_content_region(img, save_folder, base_name):
    """Tr√≠ch xu·∫•t v√πng n·ªôi dung (kh√¥ng ph·∫£i v√πng ƒëen xung quanh m√†n h√¨nh)"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    enhanced_contrast = cv2.convertScaleAbs(gray, alpha=1.3, beta=5)
    
    enhanced_path = f"{save_folder}/8b_content_enhanced_{base_name}.jpg"
    cv2.imwrite(enhanced_path, enhanced_contrast)
    
    blurred = cv2.GaussianBlur(enhanced_contrast, (3, 3), 0)
    
    sobel_x = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=3)
    sobel_y = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=3)
    gradient_mag = cv2.magnitude(sobel_x, sobel_y)
    gradient_mag = cv2.normalize(gradient_mag, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
    
    _, gradient_thresh = cv2.threshold(gradient_mag, 20, 255, cv2.THRESH_BINARY)
    
    gradient_before_path = f"{save_folder}/8b_content_gradient_before_{base_name}.jpg"
    cv2.imwrite(gradient_before_path, gradient_thresh)
    
    vertical_kernel = np.ones((11, 3), np.uint8)
    gradient_dilated = cv2.dilate(gradient_thresh, vertical_kernel, iterations=3)
    
    horizontal_kernel = np.ones((3, 9), np.uint8)
    gradient_dilated = cv2.dilate(gradient_dilated, horizontal_kernel, iterations=2)
    
    gradient_path = f"{save_folder}/8b_content_gradient_{base_name}.jpg"
    cv2.imwrite(gradient_path, gradient_dilated)
    
    kernel = np.ones((5, 5), np.uint8)
    gradient_final = cv2.morphologyEx(gradient_dilated, cv2.MORPH_CLOSE, kernel, iterations=3)
    
    gradient_final_path = f"{save_folder}/8b_content_gradient_final_{base_name}.jpg"
    cv2.imwrite(gradient_final_path, gradient_final)
    
    contours, _ = cv2.findContours(gradient_final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        enhanced_for_threshold = cv2.convertScaleAbs(gray, alpha=1.5, beta=10)
        _, thresh = cv2.threshold(enhanced_for_threshold, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        thresh_path = f"{save_folder}/8b_content_otsu_thresh_{base_name}.jpg"
        cv2.imwrite(thresh_path, thresh)
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    min_area = img.shape[0] * img.shape[1] * 0.005
    large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]
    
    all_contours_img = img.copy()
    cv2.drawContours(all_contours_img, large_contours, -1, (0, 255, 0), 2)
    all_contours_path = f"{save_folder}/8b_all_large_contours_{base_name}.jpg"
    cv2.imwrite(all_contours_path, all_contours_img)
    
    mask = np.zeros_like(gray)
    if large_contours:
        largest_contour = max(large_contours, key=cv2.contourArea)
        cv2.drawContours(mask, [largest_contour], 0, 255, -1)
    else:
        mask.fill(255)
    
    mask_path = f"{save_folder}/8b_content_final_mask_{base_name}.jpg"
    cv2.imwrite(mask_path, mask)
    
    contour_img = img.copy()
    if large_contours:
        cv2.drawContours(contour_img, [largest_contour], 0, (0, 255, 0), 2)
    contour_path = f"{save_folder}/8b_content_largest_contour_{base_name}.jpg"
    cv2.imwrite(contour_path, contour_img)
    
    return mask, large_contours[0] if large_contours else None

def fine_tune_hmi_screen(image, roi_coords, save_folder, base_name):
    """Tinh ch·ªânh v√πng m√†n h√¨nh HMI ƒë√£ ph√°t hi·ªán"""
    x_min, y_min, x_max, y_max = roi_coords
    roi = image[y_min:y_max, x_min:x_max]
    
    roi_original_path = f"{save_folder}/8b_roi_original_{base_name}.jpg"
    cv2.imwrite(roi_original_path, roi)
    
    content_mask, largest_contour = extract_content_region(roi, save_folder, base_name)
    
    if largest_contour is None:
        return roi, roi_coords
    
    contour_area = cv2.contourArea(largest_contour)
    if contour_area < 0.1 * roi.shape[0] * roi.shape[1]:
        return roi, roi_coords
    
    epsilon = 0.02 * cv2.arcLength(largest_contour, True)
    approx = cv2.approxPolyDP(largest_contour, epsilon, True)
    
    roi_approx = roi.copy()
    cv2.drawContours(roi_approx, [approx], 0, (0, 0, 255), 2)
    approx_path = f"{save_folder}/8d_roi_approx_{base_name}.jpg"
    cv2.imwrite(approx_path, roi_approx)
    
    if len(approx) != 4:
        rect = cv2.minAreaRect(largest_contour)
        box = cv2.boxPoints(rect)
        approx = np.array(box, dtype=np.int32)
        
        roi_rect = roi.copy()
        cv2.drawContours(roi_rect, [approx], 0, (255, 0, 0), 2)
        rect_path = f"{save_folder}/8e_roi_adjusted_rect_{base_name}.jpg"
        cv2.imwrite(rect_path, roi_rect)
    
    points = approx.reshape(-1, 2)
    points = order_points(points)
    
    width_a = np.sqrt(((points[2][0] - points[3][0]) ** 2) + ((points[2][1] - points[3][1]) ** 2))
    width_b = np.sqrt(((points[1][0] - points[0][0]) ** 2) + ((points[1][1] - points[0][1]) ** 2))
    max_width = max(int(width_a), int(width_b))
    
    height_a = np.sqrt(((points[1][0] - points[2][0]) ** 2) + ((points[1][1] - points[2][1]) ** 2))
    height_b = np.sqrt(((points[0][0] - points[3][0]) ** 2) + ((points[0][1] - points[3][1]) ** 2))
    max_height = max(int(height_a), int(height_b))
    
    if max_width < 10 or max_height < 10:
        return roi, roi_coords
    
    dst_points = np.array([
        [0, 0],
        [max_width - 1, 0],
        [max_width - 1, max_height - 1],
        [0, max_height - 1]
    ], dtype=np.float32)
    
    src_points = points.astype(np.float32)
    
    roi_points = roi.copy()
    for i, point in enumerate(src_points):
        cv2.circle(roi_points, tuple(point.astype(int)), 5, (0, 0, 255), -1)
        cv2.putText(roi_points, str(i), tuple(point.astype(int)), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    points_path = f"{save_folder}/8f_roi_source_points_{base_name}.jpg"
    cv2.imwrite(points_path, roi_points)
    
    M = cv2.getPerspectiveTransform(src_points, dst_points)
    warped = cv2.warpPerspective(roi, M, (max_width, max_height))
    
    warped_path = f"{save_folder}/8g_roi_warped_{base_name}.jpg"
    cv2.imwrite(warped_path, warped)
    
    new_roi_coords = (x_min, y_min, x_min + warped.shape[1], y_min + warped.shape[0])
    
    return warped, new_roi_coords

def detect_hmi_screen(image_path, save_folder):
    """Ph√°t hi·ªán v√† tr√≠ch xu·∫•t m√†n h√¨nh HMI t·ª´ ·∫£nh"""
    # ƒê·ªçc ·∫£nh
    image = cv2.imread(image_path)
    if image is None:
        print(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}")
        return None
    
    # L·∫•y t√™n c∆° s·ªü c·ªßa file ·∫£nh
    base_name = os.path.splitext(os.path.basename(image_path))[0]
    
    print("   ƒêang x·ª≠ l√Ω ·∫£nh ƒë·ªÉ ph√°t hi·ªán m√†n h√¨nh HMI...")
    
    # L∆∞u ·∫£nh g·ªëc
    original_path = f"{save_folder}/1_original_{base_name}.jpg"
    cv2.imwrite(original_path, image)
    
    # T·∫°o b·∫£n sao ƒë·ªÉ v·∫Ω k·∫øt qu·∫£
    result_image = image.copy()
    
    # B∆∞·ªõc 1: TƒÉng c∆∞·ªùng ch·∫•t l∆∞·ª£ng ·∫£nh
    enhanced_img, enhanced_clahe = enhance_image_for_hmi(image)
    enhanced_path = f"{save_folder}/2_enhanced_{base_name}.jpg"
    cv2.imwrite(enhanced_path, enhanced_img)
    
    enhanced_clahe_path = f"{save_folder}/2b_enhanced_clahe_{base_name}.jpg"
    cv2.imwrite(enhanced_clahe_path, enhanced_clahe)
    
    # B∆∞·ªõc 2: Ph√°t hi·ªán c·∫°nh
    canny_edges, sobel_edges, edges = adaptive_edge_detection(enhanced_clahe)
    
    canny_path = f"{save_folder}/3a_canny_edges_{base_name}.jpg"
    cv2.imwrite(canny_path, canny_edges)
    
    sobel_path = f"{save_folder}/3b_sobel_edges_{base_name}.jpg"
    cv2.imwrite(sobel_path, sobel_edges)
    
    edges_path = f"{save_folder}/3c_combined_edges_{base_name}.jpg"
    cv2.imwrite(edges_path, edges)
    
    # B∆∞·ªõc 3: T√¨m v√† l·ªçc contour
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    all_contours_image = image.copy()
    cv2.drawContours(all_contours_image, contours, -1, (0, 255, 0), 2)
    all_contours_path = f"{save_folder}/4a_all_contours_{base_name}.jpg"
    cv2.imwrite(all_contours_path, all_contours_image)
    
    min_contour_area = image.shape[0] * image.shape[1] * 0.001
    large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]
    
    large_contours_image = image.copy()
    cv2.drawContours(large_contours_image, large_contours, -1, (0, 255, 0), 2)
    large_contours_path = f"{save_folder}/4b_large_contours_{base_name}.jpg"
    cv2.imwrite(large_contours_path, large_contours_image)
    
    contour_mask = np.zeros_like(edges)
    cv2.drawContours(contour_mask, large_contours, -1, 255, 2)
    contour_mask_path = f"{save_folder}/4c_contour_mask_{base_name}.jpg"
    cv2.imwrite(contour_mask_path, contour_mask)
    
    # B∆∞·ªõc 4: Ph√°t hi·ªán ƒë∆∞·ªùng th·∫≥ng
    lines = cv2.HoughLinesP(contour_mask, 1, np.pi/180, threshold=25, minLineLength=15, maxLineGap=30)
    
    if lines is None or len(lines) < 2:
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=15, minLineLength=10, maxLineGap=40)
        
        if lines is None or len(lines) < 2:
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=10, minLineLength=5, maxLineGap=50)
    
    if lines is None:
        print("   ‚ö† Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng th·∫≥ng trong ·∫£nh.")
        return None
    
    all_lines_image = image.copy()
    for line in lines:
        x1, y1, x2, y2 = line[0]
        cv2.line(all_lines_image, (x1, y1), (x2, y2), (0, 0, 255), 2)
    
    all_lines_path = f"{save_folder}/5a_all_lines_{base_name}.jpg"
    cv2.imwrite(all_lines_path, all_lines_image)
    
    # B∆∞·ªõc 5: Ph√¢n lo·∫°i ƒë∆∞·ªùng ngang/d·ªçc
    height, width = image.shape[:2]
    horizontal_lines, vertical_lines = process_lines(lines, image.shape, min_length=20)
    
    if len(horizontal_lines) < 2 or len(vertical_lines) < 2:
        print("   ‚ö† Kh√¥ng t√¨m th·∫•y ƒë·ªß ƒë∆∞·ªùng ngang v√† d·ªçc.")
        result_path = f"{save_folder}/9_result_{base_name}.jpg"
        cv2.imwrite(result_path, result_image)
        return None
    
    # Th·ª≠ t√¨m h√¨nh ch·ªØ nh·∫≠t t·ª´ c√°c ƒë∆∞·ªùng ƒë√£ ph√¢n lo·∫°i
    largest_rectangle = find_rectangle_from_classified_lines(horizontal_lines, vertical_lines, image.shape)
    
    if largest_rectangle is not None:
        direct_rectangle_image = image.copy()
        pts = np.array(largest_rectangle[:4])
        cv2.polylines(direct_rectangle_image, [pts], True, (255, 255, 0), 2)
        direct_rectangle_path = f"{save_folder}/5c_direct_rectangle_{base_name}.jpg"
        cv2.imwrite(direct_rectangle_path, direct_rectangle_image)
    else:
        # N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c, ti·∫øp t·ª•c v·ªõi quy tr√¨nh th√¥ng th∆∞·ªùng
        extended_h_lines = extend_lines(horizontal_lines, width, height)
        extended_v_lines = extend_lines(vertical_lines, width, height)
        
        intersections = find_intersections(extended_h_lines, extended_v_lines)
        
        if len(intersections) < 4:
            print("   ‚ö† Kh√¥ng t√¨m th·∫•y ƒë·ªß giao ƒëi·ªÉm ƒë·ªÉ t·∫°o h√¨nh ch·ªØ nh·∫≠t.")
            result_path = f"{save_folder}/9_result_{base_name}.jpg"
            cv2.imwrite(result_path, result_image)
            return None
        
        largest_rectangle = find_largest_rectangle(intersections, image.shape)
        
        if largest_rectangle is None:
            print("   ‚ö† Kh√¥ng t√¨m th·∫•y h√¨nh ch·ªØ nh·∫≠t ph√π h·ª£p.")
            result_path = f"{save_folder}/9_result_{base_name}.jpg"
            cv2.imwrite(result_path, result_image)
            return None
    
    # X√°c ƒë·ªãnh v√πng HMI t·ª´ h√¨nh ch·ªØ nh·∫≠t l·ªõn nh·∫•t
    top_left, top_right, bottom_right, bottom_left, _ = largest_rectangle
    
    x_min = min(top_left[0], bottom_left[0])
    y_min = min(top_left[1], top_right[1])
    x_max = max(top_right[0], bottom_right[0])
    y_max = max(bottom_left[1], bottom_right[1])
    
    # Ki·ªÉm tra bi√™n
    if x_min < 0: x_min = 0
    if y_min < 0: y_min = 0
    if x_max >= image.shape[1]: x_max = image.shape[1] - 1
    if y_max >= image.shape[0]: y_max = image.shape[0] - 1
    
    if x_max > x_min and y_max > y_min:
        roi_coords = (x_min, y_min, x_max, y_max)
        
        # V·∫Ω h√¨nh ch·ªØ nh·∫≠t l√™n ·∫£nh k·∫øt qu·∫£
        cv2.rectangle(result_image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
        
        # C·∫Øt v√† l∆∞u v√πng HMI
        roi = image[y_min:y_max, x_min:x_max]
        roi_path = f"{save_folder}/8b_roi_{base_name}.jpg"
        cv2.imwrite(roi_path, roi)
        
        # Tinh ch·ªânh v√† tr·∫£i ph·∫≥ng v√πng HMI
        warped_roi, refined_coords = fine_tune_hmi_screen(image, roi_coords, save_folder, base_name)
        
        # L∆∞u ·∫£nh k·∫øt qu·∫£
        result_path = f"{save_folder}/9_result_{base_name}.jpg"
        cv2.imwrite(result_path, result_image)
        
        # L∆∞u ·∫£nh HMI ƒë√£ tr√≠ch xu·∫•t
        hmi_path = f"{save_folder}/hmi_{base_name}.jpg"
        cv2.imwrite(hmi_path, warped_roi)
        print(f"   ‚úì ƒê√£ ph√°t hi·ªán v√† tr√≠ch xu·∫•t m√†n h√¨nh HMI")
        
        return warped_roi
    
    return None

# ============================================================
# PADDLEOCR FUNCTIONS
# ============================================================

def get_ocr_instance():
    """L·∫•y ho·∫∑c t·∫°o OCR instance (singleton pattern ƒë·ªÉ tƒÉng t·ªëc)"""
    global _ocr_instance
    if _ocr_instance is None:
        print("ƒêang kh·ªüi t·∫°o PaddleOCR reader...")
        
        # Kh·ªüi t·∫°o v·ªõi suppress output ƒë·ªÉ ·∫©n th√¥ng b√°o kh√¥ng c·∫ßn thi·∫øt
        with suppress_output():
            _ocr_instance = PaddleOCR(
                lang='en',
                use_doc_orientation_classify=False,
                use_doc_unwarping=False,
                use_textline_orientation=False,
                text_det_thresh=0.15,
                text_det_box_thresh=0.25,
                text_det_unclip_ratio=2.2,
                text_rec_score_thresh=0.0,
                text_det_limit_side_len=512,
                text_det_limit_type='max',
            )
        print("‚úì Kh·ªüi t·∫°o th√†nh c√¥ng")
    return _ocr_instance

def select_image():
    """M·ªü h·ªôp tho·∫°i ch·ªçn file ·∫£nh"""
    root = tk.Tk()
    root.withdraw()
    
    file_path = filedialog.askopenfilename(
        title="Ch·ªçn ·∫£nh ƒë·ªÉ ƒë·ªçc",
        filetypes=[
            ("Image files", "*.jpg *.jpeg *.png *.bmp *.gif *.tiff"),
            ("All files", "*.*")
        ]
    )
    
    root.destroy()
    return file_path

def read_image_with_paddleocr(image_input):
    """ƒê·ªçc vƒÉn b·∫£n t·ª´ ·∫£nh b·∫±ng PaddleOCR
    
    Args:
        image_input: c√≥ th·ªÉ l√† ƒë∆∞·ªùng d·∫´n file ho·∫∑c numpy array (·∫£nh OpenCV)
    
    Returns:
        tuple: (results, img_width, img_height)
    """
    ocr = get_ocr_instance()
    
    start_time = time.time()
    
    # L·∫•y k√≠ch th∆∞·ªõc ·∫£nh
    if isinstance(image_input, np.ndarray):
        img_height, img_width = image_input.shape[:2]
        temp_path = "_temp_ocr_image.jpg"
        cv2.imwrite(temp_path, image_input)
        results = ocr.predict(temp_path)
        # X√≥a file t·∫°m
        if os.path.exists(temp_path):
            os.remove(temp_path)
    else:
        img = cv2.imread(image_input)
        if img is not None:
            img_height, img_width = img.shape[:2]
        else:
            img_height, img_width = 1, 1
        print(f"   ƒêang ƒë·ªçc OCR t·ª´ ·∫£nh...")
        results = ocr.predict(image_input)
    
    elapsed = time.time() - start_time
    print(f"   ‚úì OCR ho√†n th√†nh trong {elapsed:.2f} gi√¢y")
    
    return results, img_width, img_height

def extract_ocr_data(results):
    """Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ OCRResult objects"""
    all_data = []
    
    if not results:
        return all_data
    
    for result in results:
        if hasattr(result, 'json') and result.json:
            json_data = result.json
            res = json_data.get('res', json_data)
            
            texts = res.get('rec_texts', [])
            scores = res.get('rec_scores', [])
            polys = res.get('rec_polys', res.get('dt_polys', []))
            
            for i in range(len(texts)):
                data = {
                    'text': texts[i] if i < len(texts) else '',
                    'confidence': scores[i] if i < len(scores) else 0.0,
                    'bbox': polys[i] if i < len(polys) else []
                }
                all_data.append(data)
    
    return all_data

def write_filtered_results_to_file(filtered_results, area, machine_code, screen_name, sub_page, output_file='paddleocr_output.txt'):
    """Ghi k·∫øt qu·∫£ ƒë√£ l·ªçc (theo IoU) v√†o file txt"""
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"{'='*60}\n")
        f.write(f"AREA: {area}\n")
        f.write(f"MACHINE: {machine_code}\n")
        f.write(f"SCREEN: {screen_name}\n")
        f.write(f"SUB-PAGE: {sub_page}\n")
        f.write(f"{'='*60}\n\n")
        
        if not filtered_results:
            f.write("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ OCR ph√π h·ª£p v·ªõi c√°c ROI.\n")
            return 0
        
        for i, item in enumerate(filtered_results, 1):
            f.write(f"=== K·∫øt qu·∫£ {i} ===\n")
            f.write(f"ROI Name: {item['matched_roi']}\n")
            f.write(f"VƒÉn b·∫£n: {item['text']}\n")
            f.write(f"ƒê·ªô tin c·∫≠y: {item['confidence']:.4f}\n")
            f.write(f"IoU: {item['iou']:.2%}\n")
            f.write(f"T·ªça ƒë·ªô OCR (normalized): {item['normalized_bbox']}\n")
            f.write(f"T·ªça ƒë·ªô ROI (normalized): {item['roi_coords']}\n")
            f.write("\n")
    
    return len(filtered_results)

def print_results_summary(ocr_data, filtered_results=None, area=None, machine_code=None, screen_name=None, sub_page=None):
    """In t√≥m t·∫Øt k·∫øt qu·∫£ ra console"""
    print("\n" + "="*60)
    print("T√ìM T·∫ÆT K·∫æT QU·∫¢ OCR")
    print("="*60)
    
    if area and machine_code and screen_name:
        sub_page_info = f" (Sub-page {sub_page})" if sub_page else ""
        print(f"üéØ Screen detected: {area}/{machine_code}/{screen_name}{sub_page_info}")
        print("-"*60)
    
    if filtered_results:
        print(f"\nüìã K·∫øt qu·∫£ ƒë√£ l·ªçc theo ROI (IoU >= {IOU_THRESHOLD:.0%}):")
        print("-"*60)
        for i, item in enumerate(filtered_results, 1):
            conf_pct = item['confidence'] * 100
            iou_pct = item['iou'] * 100
            print(f"  {i:2}. [{item['matched_roi']}] \"{item['text']}\"")
            print(f"      Confidence: {conf_pct:.1f}% | IoU: {iou_pct:.1f}%")
        
        print("\n" + "="*60)
        print(f"T·ªïng c·ªông: {len(filtered_results)} k·∫øt qu·∫£ ph√π h·ª£p")
    else:
        if not ocr_data:
            print("   Kh√¥ng t√¨m th·∫•y vƒÉn b·∫£n n√†o.")
        else:
            print(f"\nüìã T·∫•t c·∫£ k·∫øt qu·∫£ OCR ({len(ocr_data)} items):")
            for i, data in enumerate(ocr_data, 1):
                conf_pct = data['confidence'] * 100
                print(f"  {i:2}. \"{data['text']}\" (confidence: {conf_pct:.1f}%)")
            print(f"\nT·ªïng c·ªông: {len(ocr_data)} k·∫øt qu·∫£")
    
    print("="*60)

def process_single_image(image_path, image_count, save_folder, selected_area=None, selected_machine=None):
    """
    X·ª≠ l√Ω m·ªôt ·∫£nh: ph√°t hi·ªán HMI -> OCR -> Match screen -> Filter by IoU
    
    Args:
        image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh
        image_count: S·ªë th·ª© t·ª± ·∫£nh
        save_folder: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
        selected_area: Khu v·ª±c ƒë√£ ch·ªçn (F1, F4, ...)
        selected_machine: M√£ m√°y ƒë√£ ch·ªçn (IE-F1-CWA01, ...)
    """
    try:
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        image_save_folder = f"{save_folder}/{base_name}_steps"
        if not os.path.exists(image_save_folder):
            os.makedirs(image_save_folder)
        
        # B∆∞·ªõc 1: Ph√°t hi·ªán v√† tr√≠ch xu·∫•t m√†n h√¨nh HMI
        print(f"\nüì∑ ƒêang x·ª≠ l√Ω ·∫£nh: {os.path.basename(image_path)}")
        if selected_area and selected_machine:
            print(f"   üéØ ƒê√£ ch·ªçn: {selected_area}/{selected_machine}")
        hmi_start = time.time()
        
        hmi_image = detect_hmi_screen(image_path, image_save_folder)
        
        hmi_time = time.time() - hmi_start
        print(f"   ‚è± Th·ªùi gian ph√°t hi·ªán HMI: {hmi_time:.2f} gi√¢y")
        
        # B∆∞·ªõc 2: Th·ª±c hi·ªán OCR tr√™n ·∫£nh HMI
        if hmi_image is not None:
            print(f"\nüîç ƒêang th·ª±c hi·ªán OCR tr√™n m√†n h√¨nh HMI ƒë√£ tr√≠ch xu·∫•t...")
            results, img_width, img_height = read_image_with_paddleocr(hmi_image)
        else:
            print(f"\n‚ö† Kh√¥ng t√¨m th·∫•y m√†n h√¨nh HMI, th·ª±c hi·ªán OCR tr√™n ·∫£nh g·ªëc...")
            results, img_width, img_height = read_image_with_paddleocr(image_path)
        
        # Tr√≠ch xu·∫•t d·ªØ li·ªáu OCR
        ocr_data = extract_ocr_data(results)
        
        # B∆∞·ªõc 3: Load ROI info v√† t√¨m screen ph√π h·ª£p
        roi_info = load_roi_info()
        
        area = None
        machine_code = None
        screen_name = None
        sub_page = None
        sub_page_data = None
        filtered_results = []
        
        if roi_info:
            print(f"\nüîé ƒêang so kh·ªõp v·ªõi Special_rois...")
            # Truy·ªÅn selected_area v√† selected_machine ƒë·ªÉ l·ªçc
            area, machine_code, screen_name, sub_page, sub_page_data, match_count, match_percentage = find_matching_screen(
                ocr_data, roi_info, 
                selected_area=selected_area, 
                selected_machine=selected_machine
            )
            
            if screen_name:
                special_rois = sub_page_data.get('Special_rois', [])
                print(f"   ‚úì T√¨m th·∫•y screen ph√π h·ª£p: {area}/{machine_code}/{screen_name} (Sub-page {sub_page})")
                print(f"   ‚úì Kh·ªõp {match_count}/{len(special_rois)} Special_rois ({match_percentage:.1f}%)")
                
                # B∆∞·ªõc 4: L·ªçc k·∫øt qu·∫£ OCR theo IoU v·ªõi ROIs
                print(f"\nüìê ƒêang t√≠nh IoU v√† l·ªçc k·∫øt qu·∫£ (threshold >= {IOU_THRESHOLD:.0%})...")
                filtered_results = filter_ocr_by_roi(ocr_data, sub_page_data, img_width, img_height)
                print(f"   ‚úì T√¨m th·∫•y {len(filtered_results)} k·∫øt qu·∫£ ph√π h·ª£p v·ªõi ROIs")
            else:
                print(f"   ‚ö† Kh√¥ng t√¨m th·∫•y screen ph√π h·ª£p trong roi_info.json")
        else:
            print(f"   ‚ö† Kh√¥ng th·ªÉ load roi_info.json")
        
        # In t√≥m t·∫Øt k·∫øt qu·∫£
        print_results_summary(ocr_data, filtered_results, area, machine_code, screen_name, sub_page)
        
        # Ghi k·∫øt qu·∫£ v√†o file
        if image_count == 1:
            output_file = 'paddleocr_output.txt'
        else:
            output_file = f'paddleocr_output_{base_name}.txt'
        
        if filtered_results:
            # Ghi k·∫øt qu·∫£ ƒë√£ l·ªçc
            count = write_filtered_results_to_file(filtered_results, area, machine_code, screen_name, sub_page, output_file)
            if count > 0:
                print(f"\n‚úì ƒê√£ ghi {count} k·∫øt qu·∫£ (ƒë√£ l·ªçc theo IoU) v√†o file: {output_file}")
            else:
                print("\n‚ö† Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o ph√π h·ª£p v·ªõi ROIs.")
        else:
            # N·∫øu kh√¥ng c√≥ filtered results, ghi t·∫•t c·∫£ k·∫øt qu·∫£ OCR
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("Kh√¥ng t√¨m th·∫•y screen ph√π h·ª£p ho·∫∑c kh√¥ng c√≥ k·∫øt qu·∫£ kh·ªõp v·ªõi ROI.\n")
                f.write("\n=== T·∫§T C·∫¢ K·∫æT QU·∫¢ OCR ===\n\n")
                for i, data in enumerate(ocr_data, 1):
                    f.write(f"=== K·∫øt qu·∫£ {i} ===\n")
                    f.write(f"VƒÉn b·∫£n: {data['text']}\n")
                    f.write(f"ƒê·ªô tin c·∫≠y: {data['confidence']:.4f}\n")
                    f.write(f"T·ªça ƒë·ªô: {data['bbox']}\n")
                    f.write("\n")
            print(f"\n‚úì ƒê√£ ghi {len(ocr_data)} k·∫øt qu·∫£ (ch∆∞a l·ªçc) v√†o file: {output_file}")
        
        return True, hmi_time
    
    except Exception as e:
        print(f"L·ªói khi x·ª≠ l√Ω ·∫£nh: {str(e)}")
        import traceback
        traceback.print_exc()
        return False, 0

def main():
    """H√†m ch√≠nh c·ªßa ch∆∞∆°ng tr√¨nh"""
    print("=" * 60)
    print("   CH∆Ø∆†NG TR√åNH PH√ÅT HI·ªÜN HMI V√Ä ƒê·ªåC OCR")
    print("   (T√≠ch h·ª£p HMI Detection + PaddleOCR + ROI Matching)")
    print("=" * 60)
    print()
    
    # T·∫°o th∆∞ m·ª•c l∆∞u ·∫£nh
    save_folder = "detected_images"
    if not os.path.exists(save_folder):
        os.makedirs(save_folder)
    
    # ============================================================
    # LOAD MACHINE SCREENS CONFIG
    # ============================================================
    machine_screens = load_machine_screens()
    if not machine_screens:
        print("‚ö† Kh√¥ng th·ªÉ load machine_screens.json. Ch∆∞∆°ng tr√¨nh s·∫Ω duy·ªát t·∫•t c·∫£ ROI.")
    
    # ============================================================
    # KH·ªûI T·∫†O PADDLEOCR 1 L·∫¶N DUY NH·∫§T
    # ============================================================
    init_start = time.time()
    
    try:
        get_ocr_instance()
    except ImportError:
        print("L·ªói: PaddleOCR ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t.")
        print("Vui l√≤ng ch·∫°y: pip install paddleocr paddlepaddle")
        return
    
    init_time = time.time() - init_start
    print(f"‚è± Th·ªùi gian kh·ªüi t·∫°o PaddleOCR: {init_time:.2f} gi√¢y")
    print()
    
    # ============================================================
    # V√íNG L·∫∂P X·ª¨ L√ù NHI·ªÄU ·∫¢NH
    # ============================================================
    image_count = 0
    total_processing_time = 0
    
    # L∆∞u l·ª±a ch·ªçn area v√† machine ƒë·ªÉ t√°i s·ª≠ d·ª•ng
    last_selected_area = None
    last_selected_machine = None
    
    while True:
        print("-" * 60)
        print(f"üìÅ Vui l√≤ng ch·ªçn ·∫£nh (ho·∫∑c Cancel ƒë·ªÉ tho√°t)...")
        image_path = select_image()
        
        if not image_path:
            print("\nüõë Kh√¥ng c√≥ ·∫£nh ƒë∆∞·ª£c ch·ªçn. K·∫øt th√∫c ch∆∞∆°ng tr√¨nh.")
            break
        
        if not os.path.exists(image_path):
            print(f"‚ö† L·ªói: Kh√¥ng t√¨m th·∫•y file ·∫£nh t·∫°i: {image_path}")
            continue
        
        # ============================================================
        # B∆Ø·ªöC CH·ªåN KHU V·ª∞C V√Ä M√É M√ÅY
        # ============================================================
        selected_area = None
        selected_machine = None
        
        if machine_screens:
            # H·ªèi c√≥ mu·ªën d√πng l·∫°i l·ª±a ch·ªçn tr∆∞·ªõc kh√¥ng
            if last_selected_area and last_selected_machine:
                print(f"\nüìå L·ª±a ch·ªçn tr∆∞·ªõc: {last_selected_area}/{last_selected_machine}")
                reuse = input("D√πng l·∫°i l·ª±a ch·ªçn n√†y? (Y/n): ").strip().lower()
                if reuse == '' or reuse == 'y':
                    selected_area = last_selected_area
                    selected_machine = last_selected_machine
                    print(f"   ‚úì S·ª≠ d·ª•ng l·∫°i: {selected_area}/{selected_machine}")
            
            # N·∫øu kh√¥ng d√πng l·∫°i, ch·ªçn m·ªõi
            if not selected_area or not selected_machine:
                # B∆∞·ªõc 1: Ch·ªçn khu v·ª±c
                selected_area = select_area(machine_screens)
                
                if selected_area:
                    # B∆∞·ªõc 2: Ch·ªçn m√£ m√°y
                    selected_machine = select_machine(machine_screens, selected_area)
                    
                    if not selected_machine:
                        # Quay l·∫°i ch·ªçn khu v·ª±c
                        print("   ‚Ü© Quay l·∫°i ch·ªçn khu v·ª±c...")
                        continue
                else:
                    # Kh√¥ng ch·ªçn khu v·ª±c - duy·ªát t·∫•t c·∫£
                    print("   ‚ö† Kh√¥ng ch·ªçn khu v·ª±c. S·∫Ω duy·ªát t·∫•t c·∫£ ROI.")
            
            # L∆∞u l·∫°i l·ª±a ch·ªçn
            if selected_area and selected_machine:
                last_selected_area = selected_area
                last_selected_machine = selected_machine
        
        image_count += 1
        process_start = time.time()
        
        # Truy·ªÅn area v√† machine ƒë√£ ch·ªçn v√†o process_single_image
        success, hmi_time = process_single_image(
            image_path, image_count, save_folder,
            selected_area=selected_area,
            selected_machine=selected_machine
        )
        
        if success:
            process_time = time.time() - process_start
            total_processing_time += process_time
            print(f"\n‚è± T·ªïng th·ªùi gian x·ª≠ l√Ω ·∫£nh n√†y: {process_time:.2f} gi√¢y")
        
        print()
    
    # ============================================================
    # TH·ªêNG K√ä CU·ªêI C√ôNG
    # ============================================================
    if image_count > 0:
        print()
        print("=" * 60)
        print("üìä TH·ªêNG K√ä T·ªîNG H·ª¢P")
        print("=" * 60)
        print(f"   ‚Ä¢ S·ªë ·∫£nh ƒë√£ x·ª≠ l√Ω: {image_count}")
        print(f"   ‚Ä¢ T·ªïng th·ªùi gian x·ª≠ l√Ω: {total_processing_time:.2f} gi√¢y")
        print(f"   ‚Ä¢ Trung b√¨nh/·∫£nh: {total_processing_time/image_count:.2f} gi√¢y")
        print(f"   ‚Ä¢ Th·ªùi gian kh·ªüi t·∫°o (1 l·∫ßn): {init_time:.2f} gi√¢y")
        print(f"   ‚Ä¢ Th∆∞ m·ª•c k·∫øt qu·∫£: {save_folder}/")
        print("=" * 60)
    
    print("\nüëã C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng ch∆∞∆°ng tr√¨nh!")

def ocr_reader(image_path):
    """Wrapper function ƒë·ªÉ ƒë·ªçc OCR"""
    results, _, _ = read_image_with_paddleocr(image_path)
    return results

if __name__ == "__main__":
    main()
